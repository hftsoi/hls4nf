{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab68a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from build_model import *\n",
    "\n",
    "'''\n",
    "Dataset: Particles\n",
    "Dataset: Particles_Classes\n",
    "Dataset: Particles_Names\n",
    "\n",
    "array([b'MET_class_1', b'Four_Ele_class_2', b'Four_Mu_class_3',\n",
    "       b'Ten_Jet_class_4'], dtype='|S16')\n",
    "       \n",
    "array([b'Pt', b'Eta', b'Phi', b'Class'], dtype='|S5')\n",
    "\n",
    "shape = (n, 19, 4)\n",
    "'''\n",
    "\n",
    "files = ['background_for_training.h5',\n",
    "         'leptoquark_LOWMASS_lepFilter_13TeV_filtered.h5',\n",
    "         'Ato4l_lepFilter_13TeV_filtered.h5',\n",
    "         'hChToTauNu_13TeV_PU20_filtered.h5',\n",
    "         'hToTauTau_13TeV_PU20_filtered.h5']\n",
    "\n",
    "sig_names = ['leptoquark', 'Ato4l', 'hChToTauNu', 'hToTauTau']\n",
    "\n",
    "data = []\n",
    "for i in range(len(files)):\n",
    "    with h5py.File('dataset/'+files[i], 'r') as hdf:\n",
    "        if i == 0:\n",
    "            data.append(hdf['Particles'][:300000])\n",
    "        else:\n",
    "            data.append(hdf['Particles'][:])\n",
    "    print(data[i].shape)\n",
    "\n",
    "data[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952014f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_data(data, 'MET')\n",
    "plot_data(data, 'Ele')\n",
    "plot_data(data, 'Mu')\n",
    "plot_data(data, 'Jet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2174e54",
   "metadata": {},
   "source": [
    "## preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56442337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove last feature (particle class), which is implicitly assumed in second index ordering\n",
    "for i in range(len(data)):\n",
    "    data[i] = np.reshape(data[i][:,:,:3], (data[i].shape[0], -1))\n",
    "\n",
    "# training data: bkg only\n",
    "X = data[0]\n",
    "\n",
    "train_ratio = 0.6\n",
    "val_ratio = 0.001\n",
    "test_ratio = 1 - train_ratio - val_ratio\n",
    "X_train_val, X_test = train_test_split(X, test_size = test_ratio, random_state = 42)\n",
    "X_train, X_val = train_test_split(X_train_val, test_size = val_ratio/(val_ratio + train_ratio), random_state = 42)\n",
    "print('X_train shape: ' + str(X_train.shape))\n",
    "print('X_val   shape: ' + str(X_val.shape))\n",
    "print('X_test  shape: ' + str(X_test.shape))\n",
    "del X_train_val\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "sig = []\n",
    "for i in range(4):\n",
    "    sig.append(scaler.transform(data[i+1]))\n",
    "\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d01348",
   "metadata": {},
   "source": [
    "## baseline ae model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4768957",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ae = build_autoencoder(input_dim=57, q=True)\n",
    "model_ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41894745",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_ae.fit(X_train, X_train, validation_data=(X_val, X_val), epochs=40, batch_size=256)\n",
    "\n",
    "plt.figure(figsize = (6,4))\n",
    "axes = plt.subplot(1,1,1)\n",
    "axes.plot(history.history['loss'], label = 'train')\n",
    "axes.plot(history.history['val_loss'], label = 'val')\n",
    "axes.legend(loc = \"upper right\")\n",
    "axes.set_xlabel('Epoch')\n",
    "axes.set_ylabel('Loss')\n",
    "\n",
    "score_bkg_ae = compute_mse_for_ae(model_ae, X_test)\n",
    "score_sig_ae = []\n",
    "for i in range(4):\n",
    "    score_sig_ae.append(compute_mse_for_ae(model_ae, sig[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170d86b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(score_bkg_ae, bins=100, alpha=0.5, label='Bkg', density=1)\n",
    "\n",
    "for i, score_vals in enumerate(score_sig_ae):\n",
    "    plt.hist(score_vals, bins=100, label=f'{sig_names[i]}', density=1, histtype='step')\n",
    "\n",
    "plt.xlabel('MSE')\n",
    "plt.xlim((0,10))\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a64a2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(4):\n",
    "    errors = np.concatenate([score_bkg_ae, score_sig_ae[i]])\n",
    "    labels = np.concatenate([np.zeros_like(score_bkg_ae), np.ones_like(score_sig_ae[i])])\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(labels, errors)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'{sig_names[i]} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "plt.xlabel('Bkg. Eff.')\n",
    "plt.ylabel('Sig. Eff.')\n",
    "plt.legend(loc='lower right')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.ylim((1e-6,1))\n",
    "plt.xlim((1e-6,1))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8f4779",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('weights/weights_ae.h5'):\n",
    "    os.remove('weights/weights_ae.h5')\n",
    "\n",
    "model_ae.save_weights('weights/weights_ae.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc650d6",
   "metadata": {},
   "source": [
    "## baseline vae model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2129bd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 60\n",
    "batch_size = 256\n",
    "beta = 0.5\n",
    "\n",
    "vae, vae_encoder, vae_decoder = build_vae(input_dim=57, beta=beta)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(10000).batch(batch_size)\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.001)\n",
    "\n",
    "train_reco_losses = []\n",
    "train_kl_losses = []\n",
    "for epoch in range(epochs):\n",
    "    epoch_reco_loss = 0\n",
    "    epoch_kl_loss = 0\n",
    "    num_batches = 0\n",
    "    for x_batch in train_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean_batch, z_log_var_batch = vae_encoder(x_batch, training=True)\n",
    "            z_batch = vae_sampling((z_mean_batch, z_log_var_batch))\n",
    "            reco = vae_decoder(z_batch, training=True)\n",
    "\n",
    "            reco_loss = tf.reduce_mean(tf.square(tf.cast(x_batch, tf.float32) - tf.cast(reco, tf.float32)))\n",
    "\n",
    "            kl_loss = -0.5 * tf.reduce_sum(1 + z_log_var_batch - tf.square(z_mean_batch) - tf.exp(z_log_var_batch), axis=-1)\n",
    "            kl_loss = tf.reduce_mean(kl_loss)\n",
    "\n",
    "            total_loss = (1 - beta) * reco_loss + beta * kl_loss\n",
    "\n",
    "        grads = tape.gradient(total_loss, vae.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, vae.trainable_variables))\n",
    "        \n",
    "        epoch_reco_loss += reco_loss.numpy()\n",
    "        epoch_kl_loss += kl_loss.numpy()\n",
    "        num_batches += 1\n",
    "\n",
    "    reco_loss_avg = epoch_reco_loss / num_batches\n",
    "    kl_loss_avg = epoch_kl_loss / num_batches\n",
    "\n",
    "    train_reco_losses.append(reco_loss_avg)\n",
    "    train_kl_losses.append(kl_loss_avg)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}: mse: {reco_loss_avg:.4f}, kl: {kl_loss_avg:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(range(1, epochs+1), train_reco_losses, label='mse')\n",
    "plt.plot(range(1, epochs+1), train_kl_losses, label='kl')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "score_bkg_vae_kl = compute_kl_for_vae(vae_encoder, X_test)\n",
    "score_bkg_vae_r  = compute_r_for_vae(vae_encoder, X_test)\n",
    "score_sig_vae_kl = []\n",
    "score_sig_vae_r = []\n",
    "for i in range(4):\n",
    "    score_sig_vae_kl.append(compute_kl_for_vae(vae_encoder, sig[i]))\n",
    "    score_sig_vae_r.append(compute_r_for_vae(vae_encoder, sig[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ffb016",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(score_bkg_vae_kl, bins=100, alpha=0.5, label='Bkg', density=True)\n",
    "\n",
    "for i, score_vals in enumerate(score_sig_vae_kl):\n",
    "    plt.hist(score_vals, bins=100, label=f'{sig_names[i]}', density=True, histtype='step')\n",
    "\n",
    "plt.xlabel('KL')\n",
    "#plt.xlim((0,10000))\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd541b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(score_bkg_vae_r, bins=100, alpha=0.5, label='Bkg', density=True)\n",
    "\n",
    "for i, score_vals in enumerate(score_sig_vae_r):\n",
    "    plt.hist(score_vals, bins=100, label=f'{sig_names[i]}', density=True, histtype='step')\n",
    "\n",
    "plt.xlabel('R_z')\n",
    "#plt.xlim((0,10000))\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ec1472",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(4):\n",
    "    errors = np.concatenate([score_bkg_vae_kl, score_sig_vae_kl[i]])\n",
    "    labels = np.concatenate([np.zeros_like(score_bkg_vae_kl), np.ones_like(score_sig_vae_kl[i])])\n",
    "    fpr, tpr, thresholds = roc_curve(labels, errors)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'{sig_names[i]} (KL) (AUC = {roc_auc:.3f})', color=colors[i], linestyle='-')\n",
    "\n",
    "    errors = np.concatenate([score_bkg_vae_r, score_sig_vae_r[i]])\n",
    "    labels = np.concatenate([np.zeros_like(score_bkg_vae_r), np.ones_like(score_sig_vae_r[i])])\n",
    "    fpr, tpr, thresholds = roc_curve(labels, errors)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'{sig_names[i]} (Rz) (AUC = {roc_auc:.3f})', color=colors[i], linestyle='--')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "plt.xlabel('Bkg. Eff.')\n",
    "plt.ylabel('Sig. Eff.')\n",
    "plt.legend(loc='lower right')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.ylim((1e-6,1))\n",
    "plt.xlim((1e-6,1))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb6b11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('weights/weights_vae_encoder.h5'):\n",
    "    os.remove('weights/weights_vae_encoder.h5')\n",
    "\n",
    "vae_encoder.save_weights('weights/weights_vae_encoder.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b748df",
   "metadata": {},
   "source": [
    "## flow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9765a9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 60\n",
    "batch_size = 256\n",
    "\n",
    "model_nf = NormalizingFlowModel(num_flows=3, q=True)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(10000).batch(batch_size)\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.001)\n",
    "\n",
    "epoch_losses = []\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    num_batches = 0\n",
    "    for x_batch in train_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = nll_loss(model_nf, x_batch)\n",
    "        grads = tape.gradient(loss, model_nf.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model_nf.trainable_variables))\n",
    "        epoch_loss += loss.numpy()\n",
    "        num_batches += 1\n",
    "    avg_loss = epoch_loss / num_batches\n",
    "    epoch_losses.append(avg_loss)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(np.arange(1, epochs+1), epoch_losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss [-log(prob density)]\")\n",
    "plt.show()\n",
    "\n",
    "score_bkg_nf = compute_nll_for_nf(model_nf, X_test)\n",
    "score_sig_nf = []\n",
    "for i in range(4):\n",
    "    score_sig_nf.append(compute_nll_for_nf(model_nf, sig[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb67815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.hist(score_bkg_nf, bins=20, alpha=0.5, label='Bkg', density=True)\n",
    "\n",
    "for i, nll_vals in enumerate(score_sig_nf):\n",
    "    plt.hist(nll_vals, bins=10000, label=f'{sig_names[i]}', density=True, histtype='step')\n",
    "\n",
    "plt.xlabel('Negative Log-Likelihood')\n",
    "plt.ylabel('Density')\n",
    "plt.xlim((-50,10000))\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58520fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(4):\n",
    "    errors = np.concatenate([score_bkg_nf, score_sig_nf[i]])\n",
    "    labels = np.concatenate([np.zeros_like(score_bkg_nf), np.ones_like(score_sig_nf[i])])\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(labels, errors)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'{sig_names[i]} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "plt.xlabel('Bkg. Eff.')\n",
    "plt.ylabel('Sig. Eff.')\n",
    "plt.legend(loc='lower right')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.ylim((1e-6,1))\n",
    "plt.xlim((1e-6,1))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e18686",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('weights/weights_nf.h5'):\n",
    "    os.remove('weights/weights_nf.h5')\n",
    "\n",
    "model_nf.save_weights('weights/weights_nf.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bf8251",
   "metadata": {},
   "source": [
    "## compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaf5a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ae = build_autoencoder(input_dim=57)\n",
    "model_ae.load_weights('weights/weights_ae.h5')\n",
    "\n",
    "score_bkg_ae = compute_mse_for_ae(model_ae, X_test)\n",
    "score_sig_ae = []\n",
    "for i in range(4):\n",
    "    score_sig_ae.append(compute_mse_for_ae(model_ae, sig[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf19564",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_encoder = build_vae(input_dim=57, beta=0.5)[1]\n",
    "vae_encoder.load_weights('weights/weights_vae_encoder.h5')\n",
    "\n",
    "score_bkg_vae_kl = compute_kl_for_vae(vae_encoder, X_test)\n",
    "score_bkg_vae_r  = compute_r_for_vae(vae_encoder, X_test)\n",
    "score_sig_vae_kl = []\n",
    "score_sig_vae_r = []\n",
    "for i in range(4):\n",
    "    score_sig_vae_kl.append(compute_kl_for_vae(vae_encoder, sig[i]))\n",
    "    score_sig_vae_r.append(compute_r_for_vae(vae_encoder, sig[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbd1334",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nf = NormalizingFlowModel(num_flows=3)\n",
    "model_nf.load_weights('weights/weights_nf.h5')\n",
    "\n",
    "score_bkg_nf = compute_nll_for_nf(model_nf, X_test)\n",
    "score_sig_nf = []\n",
    "for i in range(4):\n",
    "    score_sig_nf.append(compute_nll_for_nf(model_nf, sig[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56043bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(4):\n",
    "    errors = np.concatenate([score_bkg_nf, score_sig_nf[i]])\n",
    "    labels = np.concatenate([np.zeros_like(score_bkg_nf), np.ones_like(score_sig_nf[i])])\n",
    "    fpr, tpr, thresholds = roc_curve(labels, errors)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'{sig_names[i]} (NF) (AUC = {roc_auc:.3f})', color=colors[i], linestyle='-')\n",
    "\n",
    "    errors = np.concatenate([score_bkg_vae_kl, score_sig_vae_kl[i]])\n",
    "    labels = np.concatenate([np.zeros_like(score_bkg_vae_kl), np.ones_like(score_sig_vae_kl[i])])\n",
    "    fpr, tpr, thresholds = roc_curve(labels, errors)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'{sig_names[i]} (VAE-KL) (AUC = {roc_auc:.3f})', color=colors[i], linestyle='--')\n",
    "\n",
    "    errors = np.concatenate([score_bkg_ae, score_sig_ae[i]])\n",
    "    labels = np.concatenate([np.zeros_like(score_bkg_ae), np.ones_like(score_sig_ae[i])])\n",
    "    fpr, tpr, thresholds = roc_curve(labels, errors)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'{sig_names[i]} (AE) (AUC = {roc_auc:.3f})', color=colors[i], linestyle='.')\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "plt.xlabel('Bkg. Eff.')\n",
    "plt.ylabel('Sig. Eff.')\n",
    "plt.legend(loc='lower right')\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.ylim((1e-6,1))\n",
    "plt.xlim((1e-6,1))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8072ef",
   "metadata": {},
   "source": [
    "## hls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3418566",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nf = NormalizingFlowModel(num_flows=3)\n",
    "model_nf.load_weights('weights/weights_nf.h5')\n",
    "\n",
    "#print(\"dense 1 weights:\", model_nf.dense1.get_weights())\n",
    "#print(\"dense 2 weights:\", model_nf.dense2.get_weights())\n",
    "#print(\"dense 3 weights:\", model_nf.dense3.get_weights())\n",
    "\n",
    "for i, flow in enumerate(model_nf.flows):\n",
    "    print(f'--------flow layer {i}--------')\n",
    "    for weight in flow.weights:\n",
    "        print(f'{weight.name}: shape = {weight.shape}')\n",
    "        print(str(weight.numpy()) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f68e73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = tf.keras.Input(shape=(57,), name='x_in')\n",
    "x = model_nf.dense1(input_layer)\n",
    "x = model_nf.act1(x)\n",
    "x = model_nf.dense2(x)\n",
    "x = model_nf.act2(x)\n",
    "x = model_nf.dense3(x)\n",
    "x = model_nf.act3(x)\n",
    "model = tf.keras.Model(inputs=input_layer, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7d2ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hls4ml\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "\n",
    "config['Model']['Strategy'] = 'Latency'\n",
    "config['LayerName']['x_in']['Precision'] = 'ap_fixed<12, 4, AP_RND, AP_SAT>'\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82a029b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "    model,\n",
    "    hls_config=config,\n",
    "    project_name='model_test',\n",
    "    output_dir='model_test',\n",
    "    part='xcvu13p-flga2577-2-e',\n",
    "    io_type='io_parallel',\n",
    ")\n",
    "\n",
    "hls_model.compile()\n",
    "hls_model.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf1e554",
   "metadata": {},
   "source": [
    "## test bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c1fac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5109bbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_sig(x, sig=4):\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    decimals = sig - int(np.floor(np.log10(abs(x)))) - 1\n",
    "    return round(x, decimals)\n",
    "\n",
    "np.random.seed(42)\n",
    "#arr_in = np.zeros((3, 57))\n",
    "arr_in = np.random.uniform(low=-10, high=10, size=(3, 57))\n",
    "arr_out = np.zeros((3, 4))\n",
    "\n",
    "round_sig_vec = np.vectorize(round_sig)\n",
    "arr_in = round_sig_vec(arr_in, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10679d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_test/tb_data/tb_input_features.dat', 'w') as my_file:\n",
    "    for sample in arr_in.reshape(-1, np.prod(arr_in.shape[1:])):\n",
    "        my_file.write(' '.join(str(x) for x in sample))\n",
    "        my_file.write('\\n')\n",
    "\n",
    "with open('model_test/tb_data/tb_output_predictions.dat', 'w') as my_file:\n",
    "    for sample in arr_out.reshape(-1, np.prod(arr_out.shape[1:])):\n",
    "        my_file.write(' '.join(str(x) for x in sample))\n",
    "        my_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb2060f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
